{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Module Import\n",
        "## Module\n",
        "\n",
        "\n",
        "* numpy : ndarray\n",
        "* cv2 : image resize, 불러오기 등의 처리\n",
        "* glob : 디렉토리 파일 탐색\n",
        "* tensorflow : 모듈 설계"
      ],
      "metadata": {
        "id": "_S3m2Ayl54DA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oxye4JV62b0C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import sys\n",
        "import os\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Colab 드라이브 마운트\n",
        "##### 이후 $ cd gdrive/MyDrive/경로.. 로 기본 디렉토리 수정하여 사용\n",
        "##### 이미지 데이터를 가지고 와서 train data 라벨링 진행해야 함"
      ],
      "metadata": {
        "id": "cIeEwiRv6PfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ct7XkwXg3Q35",
        "outputId": "1708ff30-97b3-46e3-a175-ddc7f20909dd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd gdrive/MyDrive/KT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUerRhDF4Vyv",
        "outputId": "74893605-1f3e-4bc6-e6df-37d8b2f24761"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/KT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 이미지 불러오기\n",
        "##### glob.glob(path) 함수 결과를 sort하여 img데이터 들어오는 순서 고정\n",
        "##### cv2.imread() 함수로 img를 읽어오게 됨\n",
        "  - cv2.IMREAD_COLOR : 컬러 이미지 불러올 때 쓰는 옵션\n",
        "##### cv2.resize() : 크기 조절\n",
        "  - dsize를 고정함으로써 원하는 크기로 불러온 이미지 데이터 수정 가능\n",
        "\n",
        "##### 256.0으로 나누어 float데이터 타입을 유지하면서 normalize\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aaobow4Z6aq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get img list from path\n",
        "files = sorted(glob.glob(\"image/*\"))"
      ],
      "metadata": {
        "id": "dk5R2eBZ2q25"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceGn9zm94pFi",
        "outputId": "1a37edfc-44e4-4555-c8d7-f69b01ce1929"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['image/01.as', 'image/02.als', 'image/03.alskd', 'image/04.woe']"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read image from files list & reshape\n",
        "# train_img shape : ( , 256, 256, 3)\n",
        "train_img = np.array(np.array([cv2.resize(cv2.imread(file, cv2.IMREAD_COLOR), dsize=(256, 256),\n",
        "                                 interpolation=cv2.INTER_LINEAR).astype(np.float64) for file in files]))"
      ],
      "metadata": {
        "id": "A9AX9HYa2tFU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_img.shape)\n",
        "print(train_img[0].shape)\n",
        "#print(train_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpEZlnkQ2uiU",
        "outputId": "e315faf8-c486-48c0-faa0-4f979d5b2e5c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 256, 256, 3)\n",
            "(256, 256, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_label.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuvO2lAET3DN",
        "outputId": "13456a93-8501-4df7-d3a0-99130548f7fc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4,)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_label = np.array([0, 0, 1, 3])"
      ],
      "metadata": {
        "id": "bWJN8dmHTvfn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize\n",
        "train_img = train_img / (256.0)"
      ],
      "metadata": {
        "id": "VplUw2wA2v2b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture\n",
        "\n",
        "**코드가 조금 더러움 주의**\n",
        "\n",
        "기본적으로 ResNet의 구조를 가지고 있는 NN으로 구성\n",
        "## Hyperparameters\n",
        "##### **수정 불가능한 hyperparameter**\n",
        "  - input_img_shape : 256*256으로 고정\n",
        "  - input_channel : RGB 3채널 이미지\n",
        "\n",
        "##### **수정 가능한 hyperparmeter**\n",
        "  - layer1_output_channel : layer1 의 output channel개수\n",
        "  - layer1_kernel_size : ResNet 처음 conv kernel_size는 7*7 이용\n",
        "  - layer2_output_channel : layer2 의 output channel개수 (== layer1_output_channel)\n",
        "  - layer3_output_channel : layer3 의 output channel개수 (layer2_output_channel * 2)\n",
        "  - res_kernel_size : resNet에서는 기본적으로 첫번째 conv 제외 3*3 kernel로 고정\n",
        "\n",
        "## Layers\n",
        "1. layer1 : 7*7 convolution + pooling\n",
        "2. layer2 : res_unit1 * 3\n",
        "3. layer3 : res_unit2 + res_unit3 * 3\n",
        "4. flatten : 분류기에 넣기 위해 flatten진행\n",
        "5. classifier : 분류기, FC layer이용, ResNet에서는 FC layer의 Weight개수가 많으므로 한개의 FC layer만 사용\n",
        "\n",
        "### 1*1 Convolution\n",
        "layer2에서 사용하는 res_unit2의 경우, 이미지 데이터가 들어갈 때 layer2_output_channel개로 들어가지만, 나올 때 layer3_output_channel로 나오게 되는데, channel개수를 맞추어주기 위해서 convolution진행.\n",
        "이미지 크기도 res_unit2의 첫번째 convolution에서 stride (2, 2)로 진행하므로 반으로 줄어들게 되므로 1*1 convolution도 stride (2, 2)로 진행"
      ],
      "metadata": {
        "id": "9fonqlP-7Oat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "global input_img_shape, input_channel, layer1_output_channel, layer1_kernel_size, res_kernel_size, layer2_output_channel, layer3_output_channel\n",
        "input_img_shape = (256, 256, 3)\n",
        "input_channel = 3\n",
        "layer1_output_channel = 12\n",
        "layer1_kernel_size = (7, 7)\n",
        "layer2_output_channel = 12\n",
        "layer3_output_channel = 24\n",
        "\n",
        "# overall residual units num = num_residual_units * num_residual_layers \n",
        "res_kernel_size = (3, 3)"
      ],
      "metadata": {
        "id": "83CKVEPeR1TD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class cnn_model(tf.keras.Model):\n",
        "  global input_img_shape, input_channel, layer1_output_channel, layer1_kernel_size, res_kernel_size, layer2_output_channel, layer3_output_channel\n",
        "  def __init__(self):\n",
        "    super(cnn_model, self).__init__()\n",
        "    self.num_residual_units = 3 # number of units per layer\n",
        "    self.num_residual_layers = 2 # number of layer per model\n",
        "    self.res_kernel_size = (3, 3)\n",
        "\n",
        "    self.layer1 = models.Sequential(\n",
        "        [layers.Conv2D(layer1_output_channel, layer1_kernel_size, strides=(2, 2), \n",
        "                       padding='same', input_shape=input_img_shape, activation='relu'),\n",
        "         layers.MaxPool2D(pool_size=(2, 2))]\n",
        "    )\n",
        "\n",
        "    self.res_unit1 = models.Sequential(\n",
        "        [layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    self.res_unit2 = models.Sequential(\n",
        "        [layers.Conv2D(layer3_output_channel, res_kernel_size, strides=(2, 2), padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    self.res_unit3 = models.Sequential(\n",
        "        [layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "\n",
        "\n",
        "    self.flatten_layer = layers.Flatten()\n",
        "\n",
        "    self.classifier = models.Sequential(\n",
        "        [layers.Dense(4)]\n",
        "    )\n",
        "\n",
        "    self.identity = layers.Conv2D(layer3_output_channel, (1, 1), padding='same', strides=(2, 2))\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x_t = self.res_unit1(x)\n",
        "    x = x + x_t\n",
        "    x_t = self.res_unit1(x)\n",
        "    x = x + x_t\n",
        "    x_t = self.res_unit1(x)\n",
        "    x = x + x_t\n",
        "    x_t = self.res_unit2(x)\n",
        "    x = self.identity(x) + x_t\n",
        "    x_t = self.res_unit3(x)\n",
        "    x = x + x_t\n",
        "    x_t = self.res_unit3(x)\n",
        "    x = x + x_t\n",
        "    x_t = self.res_unit3(x)\n",
        "    x = x + x_t\n",
        "    x = self.flatten_layer(x)\n",
        "    x = self.classifier(x)\n",
        "    probs = tf.nn.softmax(x)\n",
        "    return probs"
      ],
      "metadata": {
        "id": "w-0NYFJ_O4lk"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = cnn_model()"
      ],
      "metadata": {
        "id": "m_F-B1R6A2g8"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model optimizer, loss등 정의 compile"
      ],
      "metadata": {
        "id": "Ct65qbqsyrX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "L8gudp5MT9Y7"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "sT8fbjD4yxjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_img, train_label, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZXKBeRnUNTu",
        "outputId": "4bc9f4fe-eab7-4e24-d18c-770daf14c072"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 2s 2s/step - loss: 4.3760 - accuracy: 0.0000e+00\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 12.2463 - accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.5279 - accuracy: 0.7500\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.9802e-08 - accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ffa03c8f210>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGT-cZKhBqvQ",
        "outputId": "70e2cd92-c901-4477-c719-15b0e245ead1"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"cnn_model_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_126 (Sequential)  (None, 64, 64, 12)       1776      \n",
            "                                                                 \n",
            " sequential_127 (Sequential)  (None, 64, 64, 12)       2712      \n",
            "                                                                 \n",
            " sequential_128 (Sequential)  (None, 64, 64, 12)       2712      \n",
            "                                                                 \n",
            " sequential_129 (Sequential)  (None, 64, 64, 12)       2712      \n",
            "                                                                 \n",
            " sequential_130 (Sequential)  (None, 32, 32, 24)       8016      \n",
            "                                                                 \n",
            " sequential_131 (Sequential)  (None, 32, 32, 24)       10608     \n",
            "                                                                 \n",
            " sequential_132 (Sequential)  (None, 32, 32, 24)       10608     \n",
            "                                                                 \n",
            " sequential_133 (Sequential)  (None, 32, 32, 24)       10608     \n",
            "                                                                 \n",
            " flatten_14 (Flatten)        multiple                  0         \n",
            "                                                                 \n",
            " sequential_134 (Sequential)  (None, 4)                98308     \n",
            "                                                                 \n",
            " conv2d_239 (Conv2D)         multiple                  312       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 148,372\n",
            "Trainable params: 147,844\n",
            "Non-trainable params: 528\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dump"
      ],
      "metadata": {
        "id": "lwMfA7Rdyzm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model(train_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xU5fCSjdBkgP",
        "outputId": "9dfb537b-e7c6-4d19-99a2-f07530c98635"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 64, 64, 12)\n",
            "(4, 64, 64, 12)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
              "array([[0.01513817, 0.87859064, 0.00146113, 0.10481004],\n",
              "       [0.02088634, 0.9301859 , 0.00163644, 0.04729134],\n",
              "       [0.05060832, 0.80482614, 0.00253833, 0.14202717],\n",
              "       [0.01934402, 0.88991696, 0.00185118, 0.08888792]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def residual_unit(self, x, in_channel, out_channel, kernel_size):\n",
        "  #   if in_channel == out_channel:\n",
        "  #     res1 = layers.Conv2D(out_channel, kernel_size, padding='same', strides=(1, 1))\n",
        "  #   else:\n",
        "  #     res1 = layers.Conv2D(out_channel, kernel_size, padding='same', strides=(2, 2))\n",
        "  #   batch1 = layers.BatchNormalization()\n",
        "  #   relu1 = layers.ReLU()\n",
        "  #   res2 = layers.Conv2D(out_channel, kernel_size, padding='same')\n",
        "  #   batch2 = layers.BatchNormalization()\n",
        "  #   relu2 = layers.ReLU()\n",
        "\n",
        "  #   x_t = res1(x)\n",
        "  #   x_t = batch1(x_t)\n",
        "  #   x_t = relu1(x_t)\n",
        "  #   x_t = res2(x_t)\n",
        "  #   x_t = batch2(x_t)\n",
        "  #   x_t = relu2(x_t)\n",
        "\n",
        "  #   if in_channel != out_channel:\n",
        "  #     identity = layers.Conv2D(out_channel, (1, 1), padding='same', strides=(2, 2))\n",
        "  #     x = identity(x)\n",
        "  #   print(x_t.shape)\n",
        "  #   print(x.shape)\n",
        "  #   return x_t + x\n",
        "\n",
        "  # channels = x.shape[3]\n",
        "    # for l in range(self.num_residual_layers):\n",
        "    #   for u in range(self.num_residual_units):\n",
        "    #     x = self.residual_unit(x, channels, (lambda x,y:channels*2 if x != 0 and y == 0 else channels)(l, u), self.res_kernel_size)\n",
        "    #     channels = channels * 2 if l != 0 and u == 0 else channels"
      ],
      "metadata": {
        "id": "MMhj8WxlrPaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape = (256, 256, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
      ],
      "metadata": {
        "id": "MYpwDLKG2xdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "5xgtV31q2yz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model information\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "4zYxbpLf2z_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "#print(model(train_img))"
      ],
      "metadata": {
        "id": "IZ_O3u7E21Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in_channel : input image channel size, out_channel : output image channel of each unit\n",
        "# kernel_size  ex) (3, 3), (5, 5), ..\n",
        "class ResidualUnit(tf.keras.Model):\n",
        "  def __init__(self, in_channel, out_channel, kernel_size, stride=False):\n",
        "    super(ResidualUnit, self).__init__()\n",
        "    if stride:\n",
        "      self.conv1 = layers.Conv2D(out_channel, kernel_size, padding='same', activation='relu', stride=(2, 2))\n",
        "    else:\n",
        "      self.conv1 = layers.Conv2D(out_channel, kernel_size, padding='same', activation='relu')\n",
        "    self.conv2 = layers.Conv2D(out_channel, kernel_size, padding='same', activation='relu')\n",
        "\n",
        "    if in_channel ==  out_channel:\n",
        "      self.identity = lambda x: x\n",
        "    else:\n",
        "      self.identity = layers.Conv2D(out_channel, (1, 1), padding='same')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    return x + self.identity(x)"
      ],
      "metadata": {
        "id": "q6_lrtijI7uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualLayer(tf.keras.Model):\n",
        "  def __init__(self, in_channel, out_channel, kernel_size, stride=False):\n",
        "    super(ResidualLayer, self).__init__()\n",
        "    # residualunit + unit + unit\n",
        "    self.res1 = ResidualUnit(in_channel, out_channel, kernel_size, stride)\n",
        "    self.res2 = ResidualUnit(out_channel, out_channel, kernel_size)\n",
        "    self.res3 = ResidualUnit(out_channel, out_channel, kernel_size)\n",
        "  \n",
        "  def call(self, x):\n",
        "    x = self.res1(x)\n",
        "    x = self.res2(x)\n",
        "    x = self.res3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "15UEkr_7NJtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class cnn_model(tf.keras.Model):\n",
        "  global input_img_shape, input_channel, layer1_output_channel, layer1_kernel_size, res_kernel_size, layer2_output_channel, layer3_output_channel\n",
        "  def __init__(self):\n",
        "    super(cnn_model, self).__init__()\n",
        "    self.num_residual_units = 3 # number of units per layer\n",
        "    self.num_residual_layers = 2 # number of layer per model\n",
        "    self.res_kernel_size = (3, 3)\n",
        "\n",
        "    self.layer1 = models.Sequential(\n",
        "        [layers.Conv2D(layer1_output_channel, layer1_kernel_size, strides=(2, 2), \n",
        "                       padding='same', input_shape=input_img_shape, activation='relu'),\n",
        "         layers.MaxPool2D(pool_size=(2, 2))]\n",
        "    )\n",
        "\n",
        "    self.unit1 = models.Sequential(\n",
        "        [layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    self.unit2 = models.Sequential(\n",
        "        [layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    self.unit3 = models.Sequential(\n",
        "        [layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    self.unit4 = models.Sequential(\n",
        "        [layers.Conv2D(layer3_output_channel, res_kernel_size, strides=(2, 2), padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    self.unit5 = models.Sequential(\n",
        "        [layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    self.unit6 = models.Sequential(\n",
        "        [layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    self.unit7 = models.Sequential(\n",
        "        [layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )   \n",
        "\n",
        "    self.flatten_layer = layers.Flatten()\n",
        "\n",
        "    self.classifier = models.Sequential(\n",
        "        [layers.Dense(4)]\n",
        "    )\n",
        "\n",
        "    self.identity = layers.Conv2D(layer3_output_channel, (1, 1), padding='same', strides=(2, 2))\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x_t = self.unit1(x)\n",
        "    x = x + x_t\n",
        "    x_t = self.unit2(x)\n",
        "    x = x + x_t\n",
        "    x_t = self.unit3(x)\n",
        "    x = x + x_t\n",
        "    x_t = self.unit4(x)\n",
        "    x = self.identity(x) + x_t\n",
        "    x_t = self.unit5(x)\n",
        "    x = x + x_t\n",
        "    x_t = self.unit6(x)\n",
        "    x = x + x_t\n",
        "    x_t = self.unit7(x)\n",
        "    x = x + x_t\n",
        "    x = self.flatten_layer(x)\n",
        "    x = self.classifier(x)\n",
        "    probs = tf.nn.softmax(x)\n",
        "    return probs"
      ],
      "metadata": {
        "id": "oy7m1ziH8YMZ"
      },
      "execution_count": 68,
      "outputs": []
    }
  ]
}