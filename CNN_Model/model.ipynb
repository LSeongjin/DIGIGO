{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S3m2Ayl54DA"
      },
      "source": [
        "# Module Import\n",
        "## Module\n",
        "\n",
        "\n",
        "* numpy : ndarray\n",
        "* cv2 : image resize, 불러오기 등의 처리\n",
        "* glob : 디렉토리 파일 탐색\n",
        "* tensorflow : 모듈 설계\n",
        "* itertools : list iterate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oxye4JV62b0C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import sys\n",
        "import os\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from itertools import chain, repeat, cycle\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIeEwiRv6PfP"
      },
      "source": [
        "# Colab 드라이브 마운트\n",
        "##### 이후 $ cd gdrive/MyDrive/경로.. 로 기본 디렉토리 수정하여 사용\n",
        "##### 이미지 데이터를 가지고 와서 train data 라벨링 진행해야 함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ct7XkwXg3Q35",
        "outputId": "07a15d89-bb73-4c76-f018-324415e5d1f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUerRhDF4Vyv",
        "outputId": "948a385c-f694-48b5-e447-99cfe8513aed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/KT\n"
          ]
        }
      ],
      "source": [
        "cd gdrive/MyDrive/KT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaobow4Z6aq6"
      },
      "source": [
        "# 이미지 불러오기\n",
        "##### glob.glob(path) 함수 결과를 sort하여 img데이터 들어오는 순서 고정\n",
        "##### cv2.imread() 함수로 img를 읽어오게 됨\n",
        "  - cv2.IMREAD_COLOR : 컬러 이미지 불러올 때 쓰는 옵션\n",
        "##### cv2.resize() : 크기 조절\n",
        "  - dsize를 고정함으로써 원하는 크기로 불러온 이미지 데이터 수정 가능\n",
        "\n",
        "##### 256.0으로 나누어 float데이터 타입을 유지하면서 normalize\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dk5R2eBZ2q25"
      },
      "outputs": [],
      "source": [
        "# get img list from path\n",
        "image_folders = sorted(glob.glob(\"Image/*\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-FqB1E2hxb5Y"
      },
      "outputs": [],
      "source": [
        "image_folders.remove('Image/info')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81Vkd8Hh-L53",
        "outputId": "40f5bfd6-3872-498a-d205-81d308435dc9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Image/01', 'Image/02', 'Image/03', 'Image/04']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "ceGn9zm94pFi"
      },
      "outputs": [],
      "source": [
        "files = []\n",
        "each_class_num = []\n",
        "for folder in image_folders:\n",
        "  temp = sorted(glob.glob(folder + \"/*.jpg\"))\n",
        "  temp.extend(sorted(glob.glob(folder + \"/*.png\")))\n",
        "  temp.extend(sorted(glob.glob(folder + \"/*.jpeg\")))\n",
        "  temp.extend(sorted(glob.glob(folder + \"/*.jfif\")))\n",
        "  files.extend(temp)\n",
        "  each_class_num.append(len(temp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g7qW0KW2tJE",
        "outputId": "ba36a150-69ce-4b50-db50-d76d1ab61cfc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[163, 196, 196, 181]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "each_class_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "A9AX9HYa2tFU"
      },
      "outputs": [],
      "source": [
        "# read image from files list & reshape\n",
        "# train_img shape : ( , 256, 256, 3)\n",
        "train_img = np.array(np.array([cv2.resize(cv2.imread(file, cv2.IMREAD_COLOR), dsize=(256, 256),\n",
        "                                 interpolation=cv2.INTER_LINEAR).astype(np.float64) for file in files]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "YoqgOQ91WL7z"
      },
      "outputs": [],
      "source": [
        "image_num = train_img.shape[0]\n",
        "labels = 4\n",
        "train_label = np.array(list(chain.from_iterable((repeat(n, k) for (n, k) in zip(range(labels), each_class_num)))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpEZlnkQ2uiU",
        "outputId": "6cad96a2-5391-4879-e21b-1746c117c8f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(736, 256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(736,)\n"
          ]
        }
      ],
      "source": [
        "print(train_img.shape)\n",
        "print(train_img[0].shape)\n",
        "print(train_label.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "VplUw2wA2v2b"
      },
      "outputs": [],
      "source": [
        "# normalize\n",
        "train_img = train_img / (256.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ZgOhCJ3kzqW7"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(train_img, train_label, test_size=0.1, stratify=train_label, random_state=34)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, stratify=y_train, random_state=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTRfdCxD35zX",
        "outputId": "ff221aa3-4a34-4ca8-8219-bef0653fdbea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(595, 256, 256, 3)\n",
            "(595,)\n",
            "(74, 256, 256, 3)\n",
            "(74,)\n",
            "(67, 256, 256, 3)\n",
            "(67,)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fonqlP-7Oat"
      },
      "source": [
        "# Model Architecture\n",
        "\n",
        "**코드가 조금 더러움 주의**\n",
        "\n",
        "기본적으로 ResNet의 구조를 가지고 있는 NN으로 구성\n",
        "## Hyperparameters\n",
        "##### **수정 불가능한 hyperparameter**\n",
        "  - input_img_shape : 256*256으로 고정\n",
        "  - input_channel : RGB 3채널 이미지\n",
        "\n",
        "##### **수정 가능한 hyperparmeter**\n",
        "  - layer1_output_channel : layer1 의 output channel개수\n",
        "  - layer1_kernel_size : ResNet 처음 conv kernel_size는 7*7 이용\n",
        "  - layer2_output_channel : layer2 의 output channel개수 (== layer1_output_channel)\n",
        "  - layer3_output_channel : layer3 의 output channel개수 (layer2_output_channel * 2)\n",
        "  - res_kernel_size : resNet에서는 기본적으로 첫번째 conv 제외 3*3 kernel로 고정\n",
        "\n",
        "## Layers\n",
        "1. layer1 : convolution + pooling\n",
        "2. layer2 : conv + norm + relu + conv + norm + relu + add\n",
        "3. layer3 : conv + norm + relu + conv + norm + relu + identity + add\n",
        "4. flatten : 분류기에 넣기 위해 flatten진행\n",
        "5. classifier : 분류기, FC layer이용, ResNet에서는 FC layer의 Weight개수가 많으므로 한개의 FC layer만 사용\n",
        "\n",
        "### 1*1 Convolution\n",
        "layer2에서 사용하는 res_unit2의 경우, 이미지 데이터가 들어갈 때 layer2_output_channel개로 들어가지만, 나올 때 layer3_output_channel로 나오게 되는데, channel개수를 맞추어주기 위해서 convolution진행.\n",
        "이미지 크기도 res_unit2의 첫번째 convolution에서 stride (2, 2)로 진행하므로 반으로 줄어들게 되므로 1*1 convolution도 stride (2, 2)로 진행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "83CKVEPeR1TD"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "global input_img_shape, input_channel, layer1_output_channel, layer1_kernel_size, res_kernel_size, layer2_output_channel, layer3_output_channel\n",
        "input_img_shape = (256, 256, 3)\n",
        "input_channel = 3\n",
        "layer1_output_channel = 6\n",
        "layer1_kernel_size = (7, 7)\n",
        "layer2_output_channel = 6\n",
        "layer3_output_channel = 12\n",
        "\n",
        "# overall residual units num = num_residual_units * num_residual_layers \n",
        "res_kernel_size = (11, 11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "892Gl70xF178"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.keras.activations import softmax\n",
        "class cnn_model(tf.keras.Model):\n",
        "  global input_img_shape, input_channel, layer1_output_channel, layer1_kernel_size, res_kernel_size, layer2_output_channel, layer3_output_channel\n",
        "  def __init__(self):\n",
        "    super(cnn_model, self).__init__()\n",
        "    \n",
        "    self.conv1 = layers.Conv2D(layer1_output_channel, layer1_kernel_size, strides=(2, 2), \n",
        "                       padding='same', input_shape=input_img_shape, activation='relu')\n",
        "    self.pool1 = layers.MaxPool2D(pool_size=(4, 4))\n",
        "    self.conv2_t = layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same')\n",
        "    self.batchnorm1 = layers.BatchNormalization()\n",
        "    self.relu1 = layers.ReLU()\n",
        "    self.conv2 = layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same')\n",
        "    self.batchnorm2 = layers.BatchNormalization()\n",
        "    self.relu2 = layers.ReLU()\n",
        "    self.add1 = layers.Add()\n",
        "    \n",
        "    self.conv3 = layers.Conv2D(layer3_output_channel, res_kernel_size, strides=(2, 2), padding='same')\n",
        "    self.batchnorm3 = layers.BatchNormalization()\n",
        "    self.relu3 = layers.ReLU()\n",
        "    \n",
        "    self.conv4 = layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same')\n",
        "    self.batchnorm4 = layers.BatchNormalization()\n",
        "    self.relu4 = layers.ReLU()\n",
        "    self.identity = layers.Conv2D(layer3_output_channel, (1, 1), padding='same', strides=(2, 2))\n",
        "    self.add2 = layers.Add()\n",
        "    \n",
        "    self.flat = layers.Flatten()\n",
        "    self.fc1 = layers.Dense(4)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.pool1(x)\n",
        "    x_t = self.conv2_t(x)\n",
        "    x_t = self.batchnorm1(x_t)\n",
        "    x_t = self.relu1(x_t)\n",
        "    x_t = self.conv2(x_t)\n",
        "    x_t = self.batchnorm2(x_t)\n",
        "    x_t = self.relu2(x_t)\n",
        "    x = self.add1([x, x_t])\n",
        "\n",
        "    x_t = self.conv3(x)\n",
        "    x_t = self.batchnorm3(x_t)\n",
        "    x_t = self.relu3(x_t)\n",
        "    x_t = self.conv4(x_t)\n",
        "    x_t = self.batchnorm4(x_t)\n",
        "    x_t = self.relu4(x_t)\n",
        "    x = self.identity(x)\n",
        "    x = self.add2([x, x_t])\n",
        "    x = self.flat(x)\n",
        "    x = self.fc1(x)\n",
        "    probs = softmax(x)\n",
        "    return probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "m_F-B1R6A2g8"
      },
      "outputs": [],
      "source": [
        "model = cnn_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct65qbqsyrX9"
      },
      "source": [
        "model optimizer, loss등 정의 compile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "L8gudp5MT9Y7"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT8fbjD4yxjs"
      },
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "v6KAI2UG4gl8"
      },
      "outputs": [],
      "source": [
        "# Train Hyperparameters\n",
        "epoch = 50\n",
        "batch = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEFStN575NmW",
        "outputId": "d572b64a-ba8b-4182-d142-939334fc4d86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(595, 256, 256, 3)\n",
            "(595,)\n",
            "(74, 256, 256, 3)\n",
            "(74,)\n",
            "(67, 256, 256, 3)\n",
            "(67,)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "kYyYZywR5vYQ"
      },
      "outputs": [],
      "source": [
        "filename = 'checkpoint.ckpt'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "earlystopping = EarlyStopping(monitor='val_loss', patience=20)\n",
        "# , callbacks=[checkpoint, earlystopping]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZXKBeRnUNTu",
        "outputId": "1966eebc-49cb-432c-fa4c-c5719c47c463"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.3399 - accuracy: 0.5109\n",
            "Epoch 00001: val_loss improved from inf to 1.80360, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 3s 75ms/step - loss: 1.3399 - accuracy: 0.5109 - val_loss: 1.8036 - val_accuracy: 0.2537\n",
            "Epoch 2/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.6203 - accuracy: 0.7815\n",
            "Epoch 00002: val_loss improved from 1.80360 to 1.35779, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 44ms/step - loss: 0.6203 - accuracy: 0.7815 - val_loss: 1.3578 - val_accuracy: 0.4179\n",
            "Epoch 3/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.4989 - accuracy: 0.8185\n",
            "Epoch 00003: val_loss improved from 1.35779 to 1.13716, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 46ms/step - loss: 0.4989 - accuracy: 0.8185 - val_loss: 1.1372 - val_accuracy: 0.4925\n",
            "Epoch 4/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.3487 - accuracy: 0.8672\n",
            "Epoch 00004: val_loss improved from 1.13716 to 1.13498, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.3487 - accuracy: 0.8672 - val_loss: 1.1350 - val_accuracy: 0.3731\n",
            "Epoch 5/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.2854 - accuracy: 0.9059\n",
            "Epoch 00005: val_loss improved from 1.13498 to 0.94373, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 46ms/step - loss: 0.2854 - accuracy: 0.9059 - val_loss: 0.9437 - val_accuracy: 0.5672\n",
            "Epoch 6/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.2198 - accuracy: 0.9261\n",
            "Epoch 00006: val_loss improved from 0.94373 to 0.88203, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 48ms/step - loss: 0.2198 - accuracy: 0.9261 - val_loss: 0.8820 - val_accuracy: 0.5672\n",
            "Epoch 7/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.1668 - accuracy: 0.9479\n",
            "Epoch 00007: val_loss improved from 0.88203 to 0.79555, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 46ms/step - loss: 0.1668 - accuracy: 0.9479 - val_loss: 0.7956 - val_accuracy: 0.6119\n",
            "Epoch 8/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.1124 - accuracy: 0.9630\n",
            "Epoch 00008: val_loss did not improve from 0.79555\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 0.1124 - accuracy: 0.9630 - val_loss: 0.8383 - val_accuracy: 0.5970\n",
            "Epoch 9/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.1042 - accuracy: 0.9714\n",
            "Epoch 00009: val_loss did not improve from 0.79555\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 0.1042 - accuracy: 0.9714 - val_loss: 0.8901 - val_accuracy: 0.6269\n",
            "Epoch 10/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.1491 - accuracy: 0.9513\n",
            "Epoch 00010: val_loss improved from 0.79555 to 0.74406, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 46ms/step - loss: 0.1491 - accuracy: 0.9513 - val_loss: 0.7441 - val_accuracy: 0.6269\n",
            "Epoch 11/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9748\n",
            "Epoch 00011: val_loss improved from 0.74406 to 0.34601, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 47ms/step - loss: 0.0836 - accuracy: 0.9748 - val_loss: 0.3460 - val_accuracy: 0.8955\n",
            "Epoch 12/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0649 - accuracy: 0.9815\n",
            "Epoch 00012: val_loss did not improve from 0.34601\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 0.0649 - accuracy: 0.9815 - val_loss: 0.3778 - val_accuracy: 0.8060\n",
            "Epoch 13/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9866\n",
            "Epoch 00013: val_loss did not improve from 0.34601\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 0.0434 - accuracy: 0.9866 - val_loss: 0.4067 - val_accuracy: 0.8358\n",
            "Epoch 14/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9950\n",
            "Epoch 00014: val_loss improved from 0.34601 to 0.30275, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.0240 - accuracy: 0.9950 - val_loss: 0.3028 - val_accuracy: 0.8806\n",
            "Epoch 15/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.9899\n",
            "Epoch 00015: val_loss did not improve from 0.30275\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 0.0398 - accuracy: 0.9899 - val_loss: 0.8115 - val_accuracy: 0.6866\n",
            "Epoch 16/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 1.0000\n",
            "Epoch 00016: val_loss did not improve from 0.30275\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.4823 - val_accuracy: 0.7910\n",
            "Epoch 17/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9983\n",
            "Epoch 00017: val_loss did not improve from 0.30275\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 0.0179 - accuracy: 0.9983 - val_loss: 0.3653 - val_accuracy: 0.8358\n",
            "Epoch 18/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9983\n",
            "Epoch 00018: val_loss improved from 0.30275 to 0.28000, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 46ms/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 0.2800 - val_accuracy: 0.8657\n",
            "Epoch 19/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 00019: val_loss improved from 0.28000 to 0.24395, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.8806\n",
            "Epoch 20/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 00020: val_loss did not improve from 0.24395\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.8806\n",
            "Epoch 21/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 00021: val_loss improved from 0.24395 to 0.23537, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.8806\n",
            "Epoch 22/50\n",
            "18/19 [===========================>..] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 00022: val_loss did not improve from 0.23537\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.8955\n",
            "Epoch 23/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 00023: val_loss improved from 0.23537 to 0.22560, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 47ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9254\n",
            "Epoch 24/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 00024: val_loss did not improve from 0.22560\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9104\n",
            "Epoch 25/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 00025: val_loss did not improve from 0.22560\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.8955\n",
            "Epoch 26/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 00026: val_loss did not improve from 0.22560\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.9104\n",
            "Epoch 27/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 00027: val_loss did not improve from 0.22560\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.9254\n",
            "Epoch 28/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 00028: val_loss did not improve from 0.22560\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9403\n",
            "Epoch 29/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 00029: val_loss did not improve from 0.22560\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9254\n",
            "Epoch 30/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 00030: val_loss did not improve from 0.22560\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9254\n",
            "Epoch 31/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 00031: val_loss did not improve from 0.22560\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9403\n",
            "Epoch 32/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 9.5758e-04 - accuracy: 1.0000\n",
            "Epoch 00032: val_loss did not improve from 0.22560\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 9.5758e-04 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9254\n",
            "Epoch 33/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 8.0288e-04 - accuracy: 1.0000\n",
            "Epoch 00033: val_loss did not improve from 0.22560\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 8.0288e-04 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9104\n",
            "Epoch 34/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 7.9104e-04 - accuracy: 1.0000\n",
            "Epoch 00034: val_loss did not improve from 0.22560\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 7.9104e-04 - accuracy: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.9254\n",
            "Epoch 35/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 6.9228e-04 - accuracy: 1.0000\n",
            "Epoch 00035: val_loss did not improve from 0.22560\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 6.9228e-04 - accuracy: 1.0000 - val_loss: 0.2749 - val_accuracy: 0.9254\n",
            "Epoch 36/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 8.6089e-04 - accuracy: 1.0000\n",
            "Epoch 00036: val_loss did not improve from 0.22560\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 8.6089e-04 - accuracy: 1.0000 - val_loss: 0.2867 - val_accuracy: 0.9254\n",
            "Epoch 37/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 6.4149e-04 - accuracy: 1.0000\n",
            "Epoch 00037: val_loss did not improve from 0.22560\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 6.4149e-04 - accuracy: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.9403\n",
            "Epoch 38/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 7.8870e-04 - accuracy: 1.0000\n",
            "Epoch 00038: val_loss did not improve from 0.22560\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 7.8870e-04 - accuracy: 1.0000 - val_loss: 0.2748 - val_accuracy: 0.9403\n",
            "Epoch 39/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 9.4118e-04 - accuracy: 1.0000\n",
            "Epoch 00039: val_loss did not improve from 0.22560\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 9.4118e-04 - accuracy: 1.0000 - val_loss: 0.3215 - val_accuracy: 0.8955\n",
            "Epoch 40/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 00040: val_loss did not improve from 0.22560\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.9403\n",
            "Epoch 41/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000    \n",
            "Epoch 00041: val_loss did not improve from 0.22560\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2931 - val_accuracy: 0.9104\n",
            "Epoch 42/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 5.5067e-04 - accuracy: 1.0000\n",
            "Epoch 00042: val_loss did not improve from 0.22560\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 5.5067e-04 - accuracy: 1.0000 - val_loss: 0.3371 - val_accuracy: 0.9403\n",
            "Epoch 43/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 5.6220e-04 - accuracy: 1.0000\n",
            "Epoch 00043: val_loss did not improve from 0.22560\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 5.6220e-04 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.9254\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x_train, y_train, epochs=epoch, validation_data=(x_val, y_val) , callbacks=[checkpoint, earlystopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "BKGxiqTMe2Se"
      },
      "outputs": [],
      "source": [
        "model_fi = cnn_model()\n",
        "model_fi.load_weights(filename)\n",
        "model_fi.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "Wct1WJOD4uOW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "127673e5-2f46-4f41-bde1-f526ac1b0d08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 1s 60ms/step - loss: 0.3195 - accuracy: 0.9189\n"
          ]
        }
      ],
      "source": [
        "results = model_fi.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "LuHBsYsk40Qt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a36cd91-3a28-4174-a4e1-4b9fcef62a5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss, test acc: [0.31953859329223633, 0.9189189076423645]\n"
          ]
        }
      ],
      "source": [
        "print('test loss, test acc:', results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGT-cZKhBqvQ",
        "outputId": "0c155de2-b57e-47f9-db97-703e62b551db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"cnn_model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_42 (Conv2D)          multiple                  888       \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  multiple                 0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          multiple                  4362      \n",
            "                                                                 \n",
            " batch_normalization_28 (Bat  multiple                 24        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_28 (ReLU)             multiple                  0         \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          multiple                  4362      \n",
            "                                                                 \n",
            " batch_normalization_29 (Bat  multiple                 24        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_29 (ReLU)             multiple                  0         \n",
            "                                                                 \n",
            " add_14 (Add)                multiple                  0         \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          multiple                  8724      \n",
            "                                                                 \n",
            " batch_normalization_30 (Bat  multiple                 48        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_30 (ReLU)             multiple                  0         \n",
            "                                                                 \n",
            " conv2d_46 (Conv2D)          multiple                  17436     \n",
            "                                                                 \n",
            " batch_normalization_31 (Bat  multiple                 48        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_31 (ReLU)             multiple                  0         \n",
            "                                                                 \n",
            " conv2d_47 (Conv2D)          multiple                  84        \n",
            "                                                                 \n",
            " add_15 (Add)                multiple                  0         \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         multiple                  0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             multiple                  12292     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 48,292\n",
            "Trainable params: 48,220\n",
            "Non-trainable params: 72\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_fi.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWOqab0csQye"
      },
      "outputs": [],
      "source": [
        "model_fi.save('cnnmodel')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rbu_72pkdj1"
      },
      "outputs": [],
      "source": [
        "loaded = tf.keras.models.load_model('cnnmodel')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgdP-FI9shZO",
        "outputId": "833364a7-238f-4ac4-eb58-a446af4a2544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 430ms/step - loss: 0.4683 - accuracy: 0.9048\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4682854115962982, 0.9047619104385376]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "loaded.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwMfA7Rdyzm-"
      },
      "source": [
        "#Dump"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xU5fCSjdBkgP"
      },
      "outputs": [],
      "source": [
        "model(train_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMhj8WxlrPaS"
      },
      "outputs": [],
      "source": [
        "# def residual_unit(self, x, in_channel, out_channel, kernel_size):\n",
        "  #   if in_channel == out_channel:\n",
        "  #     res1 = layers.Conv2D(out_channel, kernel_size, padding='same', strides=(1, 1))\n",
        "  #   else:\n",
        "  #     res1 = layers.Conv2D(out_channel, kernel_size, padding='same', strides=(2, 2))\n",
        "  #   batch1 = layers.BatchNormalization()\n",
        "  #   relu1 = layers.ReLU()\n",
        "  #   res2 = layers.Conv2D(out_channel, kernel_size, padding='same')\n",
        "  #   batch2 = layers.BatchNormalization()\n",
        "  #   relu2 = layers.ReLU()\n",
        "\n",
        "  #   x_t = res1(x)\n",
        "  #   x_t = batch1(x_t)\n",
        "  #   x_t = relu1(x_t)\n",
        "  #   x_t = res2(x_t)\n",
        "  #   x_t = batch2(x_t)\n",
        "  #   x_t = relu2(x_t)\n",
        "\n",
        "  #   if in_channel != out_channel:\n",
        "  #     identity = layers.Conv2D(out_channel, (1, 1), padding='same', strides=(2, 2))\n",
        "  #     x = identity(x)\n",
        "  #   print(x_t.shape)\n",
        "  #   print(x.shape)\n",
        "  #   return x_t + x\n",
        "\n",
        "  # channels = x.shape[3]\n",
        "    # for l in range(self.num_residual_layers):\n",
        "    #   for u in range(self.num_residual_units):\n",
        "    #     x = self.residual_unit(x, channels, (lambda x,y:channels*2 if x != 0 and y == 0 else channels)(l, u), self.res_kernel_size)\n",
        "    #     channels = channels * 2 if l != 0 and u == 0 else channels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYpwDLKG2xdk"
      },
      "outputs": [],
      "source": [
        "# model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape = (256, 256, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xgtV31q2yz_"
      },
      "outputs": [],
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zYxbpLf2z_A"
      },
      "outputs": [],
      "source": [
        "# model information\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZ_O3u7E21Iu"
      },
      "outputs": [],
      "source": [
        "#model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "#print(model(train_img))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6_lrtijI7uk"
      },
      "outputs": [],
      "source": [
        "# in_channel : input image channel size, out_channel : output image channel of each unit\n",
        "# kernel_size  ex) (3, 3), (5, 5), ..\n",
        "class ResidualUnit(tf.keras.Model):\n",
        "  def __init__(self, in_channel, out_channel, kernel_size, stride=False):\n",
        "    super(ResidualUnit, self).__init__()\n",
        "    if stride:\n",
        "      self.conv1 = layers.Conv2D(out_channel, kernel_size, padding='same', activation='relu', stride=(2, 2))\n",
        "    else:\n",
        "      self.conv1 = layers.Conv2D(out_channel, kernel_size, padding='same', activation='relu')\n",
        "    self.conv2 = layers.Conv2D(out_channel, kernel_size, padding='same', activation='relu')\n",
        "\n",
        "    if in_channel ==  out_channel:\n",
        "      self.identity = lambda x: x\n",
        "    else:\n",
        "      self.identity = layers.Conv2D(out_channel, (1, 1), padding='same')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    return x + self.identity(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15UEkr_7NJtK"
      },
      "outputs": [],
      "source": [
        "class ResidualLayer(tf.keras.Model):\n",
        "  def __init__(self, in_channel, out_channel, kernel_size, stride=False):\n",
        "    super(ResidualLayer, self).__init__()\n",
        "    # residualunit + unit + unit\n",
        "    self.res1 = ResidualUnit(in_channel, out_channel, kernel_size, stride)\n",
        "    self.res2 = ResidualUnit(out_channel, out_channel, kernel_size)\n",
        "    self.res3 = ResidualUnit(out_channel, out_channel, kernel_size)\n",
        "  \n",
        "  def call(self, x):\n",
        "    x = self.res1(x)\n",
        "    x = self.res2(x)\n",
        "    x = self.res3(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-0NYFJ_O4lk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.keras.activations import softmax\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(layer1_output_channel, (11, 11), activation='relu', input_shape = (256, 256, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(layer2_output_channel, (7, 7), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#model.add(layers.Conv2D(layer3_output_channel, (7, 7), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(4, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKkhFVOmHfkT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.keras.activations import softmax\n",
        "class cnn_model(tf.keras.Model):\n",
        "  global input_img_shape, input_channel, layer1_output_channel, layer1_kernel_size, res_kernel_size, layer2_output_channel, layer3_output_channel\n",
        "  def __init__(self):\n",
        "    super(cnn_model, self).__init__()\n",
        "    self.num_residual_units = 3 # number of units per layer\n",
        "    self.num_residual_layers = 2 # number of layer per model\n",
        "    self.res_kernel_size = (3, 3)\n",
        "\n",
        "    self.layer1 = models.Sequential(\n",
        "        [\n",
        "         layers.Conv2D(layer1_output_channel, layer1_kernel_size, strides=(2, 2), \n",
        "                       padding='same', input_shape=input_img_shape, activation='relu'),\n",
        "         layers.MaxPool2D(pool_size=(4, 4))]\n",
        "    )\n",
        "\n",
        "    self.res_unit1 = models.Sequential(\n",
        "        [layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "    '''\n",
        "\n",
        "    self.res_unit2 = models.Sequential(\n",
        "        [layers.Conv2D(layer3_output_channel, res_kernel_size, strides=(2, 2), padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    self.res_unit3 = models.Sequential(\n",
        "        [layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )'''\n",
        "\n",
        "    #self.identity = layers.Conv2D(layer3_output_channel, (1, 1), padding='same', strides=(2, 2))\n",
        "\n",
        "    self.flatten_layer = layers.Flatten()\n",
        "\n",
        "    self.classifier = models.Sequential(\n",
        "        [layers.Dense(4)]\n",
        "    )\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x_t = self.res_unit1(x)\n",
        "    x = x + x_t\n",
        "    #x_t = self.res_unit1(x)\n",
        "    #x = x + x_t\n",
        "    #x_t = self.res_unit1(x)\n",
        "    #x = x + x_t\n",
        "    #x_t = self.res_unit2(x)\n",
        "    #x = self.identity(x) + x_t\n",
        "    #x_t = self.res_unit3(x)\n",
        "    #x = x + x_t\n",
        "    #x_t = self.res_unit3(x)\n",
        "    #x = x + x_t\n",
        "    #x_t = self.res_unit3(x)\n",
        "    #x = x + x_t\n",
        "    x = self.flatten_layer(x)\n",
        "    x = self.classifier(x)\n",
        "    probs = softmax(x)\n",
        "    return probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy7m1ziH8YMZ"
      },
      "outputs": [],
      "source": [
        "class cnn_model(tf.keras.Model):\n",
        "  global input_img_shape, input_channel, layer1_output_channel, layer1_kernel_size, res_kernel_size, layer2_output_channel, layer3_output_channel\n",
        "  def __init__(self):\n",
        "    super(cnn_model, self).__init__()\n",
        "\n",
        "    self.layer1 = models.Sequential(\n",
        "        [layers.Conv2D(layer1_output_channel, layer1_kernel_size, strides=(2, 2), \n",
        "                       padding='same', input_shape=input_img_shape, activation='relu'),\n",
        "         layers.MaxPool2D(pool_size=(2, 2))]\n",
        "    )\n",
        "\n",
        "    self.unit1 = models.Sequential(\n",
        "        [layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "    '''\n",
        "    self.unit2 = models.Sequential(\n",
        "        [layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    self.unit3 = models.Sequential(\n",
        "        [layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "    '''\n",
        "\n",
        "    self.unit4 = models.Sequential(\n",
        "        [layers.Conv2D(layer3_output_channel, res_kernel_size, strides=(2, 2), padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    '''self.unit5 = models.Sequential(\n",
        "        [layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    self.unit6 = models.Sequential(\n",
        "        [layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    self.unit7 = models.Sequential(\n",
        "        [layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )   '''\n",
        "    self.identity = layers.Conv2D(layer3_output_channel, (1, 1), padding='same', strides=(2, 2))\n",
        "    self.flatten_layer = layers.Flatten()\n",
        "\n",
        "    self.classifier = models.Sequential(\n",
        "        [layers.Dense(4)]\n",
        "    )\n",
        "\n",
        "    \n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.unit1(x)\n",
        "    #x = x + x_t\n",
        "    #x_t = self.unit2(x)\n",
        "    #x = x + x_t\n",
        "    #x_t = self.unit3(x)\n",
        "    #x = x + x_t\n",
        "    x = self.unit4(x)\n",
        "    #x = self.identity(x) + x_t\n",
        "    #x_t = self.unit5(x)\n",
        "    #x = x + x_t\n",
        "    #x_t = self.unit6(x)\n",
        "    #x = x + x_t\n",
        "    #x_t = self.unit7(x)\n",
        "    #x = x + x_t\n",
        "    x = self.flatten_layer(x)\n",
        "    x = self.classifier(x)\n",
        "    probs = tf.nn.softmax(x)\n",
        "    return probs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.activations import softmax\n",
        "class cnn_model(tf.keras.Model):\n",
        "  global input_img_shape, input_channel, layer1_output_channel, layer1_kernel_size, res_kernel_size, layer2_output_channel, layer3_output_channel\n",
        "  def __init__(self):\n",
        "    super(cnn_model, self).__init__()\n",
        "    \n",
        "    self.conv1 = layers.Conv2D(layer1_output_channel, layer1_kernel_size, strides=(2, 2), \n",
        "                       padding='same', input_shape=input_img_shape, activation='relu')\n",
        "    self.pool1 = layers.MaxPool2D(pool_size=(4, 4))\n",
        "    self.conv2_t = layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same')\n",
        "    self.batchnorm1 = layers.BatchNormalization()\n",
        "    self.relu1 = layers.ReLU()\n",
        "    self.conv2 = layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same')\n",
        "    self.batchnorm2 = layers.BatchNormalization()\n",
        "    self.relu2 = layers.ReLU()\n",
        "    self.add1 = layers.Add()\n",
        "    \n",
        "    self.conv3 = layers.Conv2D(layer3_output_channel, res_kernel_size, strides=(2, 2), padding='same')\n",
        "    self.batchnorm3 = layers.BatchNormalization()\n",
        "    self.relu3 = layers.ReLU()\n",
        "    \n",
        "    self.conv4 = layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same')\n",
        "    self.batchnorm4 = layers.BatchNormalization()\n",
        "    self.relu4 = layers.ReLU()\n",
        "    self.identity = layers.Conv2D(layer3_output_channel, (1, 1), padding='same', strides=(2, 2))\n",
        "    self.add2 = layers.Add()\n",
        "    \n",
        "    self.flat = layers.Flatten()\n",
        "    self.fc1 = layers.Dense(4)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.pool1(x)\n",
        "    x_t = self.conv2_t(x)\n",
        "    x_t = self.batchnorm1(x_t)\n",
        "    x_t = self.relu1(x_t)\n",
        "    x_t = self.conv2(x_t)\n",
        "    x_t = self.batchnorm2(x_t)\n",
        "    x_t = self.relu2(x_t)\n",
        "    x = self.add1([x, x_t])\n",
        "\n",
        "    x_t = self.conv3(x_t)\n",
        "    x_t = self.batchnorm3(x_t)\n",
        "    x_t = self.relu3(x_t)\n",
        "    x_t = self.conv4(x_t)\n",
        "    x_t = self.batchnorm4(x_t)\n",
        "    x_t = self.relu4(x_t)\n",
        "    x = self.identity(x)\n",
        "    x = self.add2([x, x_t])\n",
        "    x = self.flat(x)\n",
        "    x = self.fc1(x)\n",
        "    probs = softmax(x)\n",
        "    return probs"
      ],
      "metadata": {
        "id": "TTAlLSodzLyU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}