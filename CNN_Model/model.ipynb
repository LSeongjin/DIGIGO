{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S3m2Ayl54DA"
      },
      "source": [
        "# Module Import\n",
        "## Module\n",
        "\n",
        "\n",
        "* numpy : ndarray\n",
        "* cv2 : image resize, 불러오기 등의 처리\n",
        "* glob : 디렉토리 파일 탐색\n",
        "* tensorflow : 모듈 설계\n",
        "* itertools : list iterate\n",
        "* sklearn : dataset split (train, validation, test data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oxye4JV62b0C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import sys\n",
        "import os\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from itertools import chain, repeat, cycle\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIeEwiRv6PfP"
      },
      "source": [
        "# Colab 드라이브 마운트\n",
        "##### 이후 $ cd gdrive/MyDrive/경로.. 로 기본 디렉토리 수정하여 사용\n",
        "##### 이미지 데이터를 가지고 와서 train data 라벨링 진행해야 함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ct7XkwXg3Q35",
        "outputId": "5af85c54-f41a-4173-c06a-ddea50a819cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUerRhDF4Vyv",
        "outputId": "28311a2e-34e3-4f02-cc83-55d86ad839c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/KT\n"
          ]
        }
      ],
      "source": [
        "cd gdrive/MyDrive/KT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaobow4Z6aq6"
      },
      "source": [
        "# 이미지 불러오기\n",
        "##### glob.glob(path) 함수 결과를 sort하여 img데이터 들어오는 순서 고정\n",
        "##### cv2.imread() 함수로 img를 읽어오게 됨\n",
        "  - cv2.IMREAD_COLOR : 컬러 이미지 불러올 때 쓰는 옵션\n",
        "##### cv2.resize() : 크기 조절\n",
        "  - dsize를 고정함으로써 원하는 크기로 불러온 이미지 데이터 수정 가능\n",
        "\n",
        "##### 256.0으로 나누어 float데이터 타입을 유지하면서 normalize\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dk5R2eBZ2q25"
      },
      "outputs": [],
      "source": [
        "# get img list from path\n",
        "image_folders = sorted(glob.glob(\"Image/*\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-FqB1E2hxb5Y"
      },
      "outputs": [],
      "source": [
        "# remove non-image file\n",
        "image_folders.remove('Image/info')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ceGn9zm94pFi"
      },
      "outputs": [],
      "source": [
        "# get all the image file from train data\n",
        "files = []\n",
        "each_class_num = []\n",
        "for folder in image_folders:\n",
        "  temp = sorted(glob.glob(folder + \"/*.jpg\"))\n",
        "  temp.extend(sorted(glob.glob(folder + \"/*.png\")))\n",
        "  temp.extend(sorted(glob.glob(folder + \"/*.jpeg\")))\n",
        "  temp.extend(sorted(glob.glob(folder + \"/*.jfif\")))\n",
        "  files.extend(temp)\n",
        "  each_class_num.append(len(temp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "A9AX9HYa2tFU"
      },
      "outputs": [],
      "source": [
        "# read image from files list & reshape\n",
        "# train_img shape : ( , 256, 256, 3)\n",
        "train_img = np.array(np.array([cv2.resize(cv2.imread(file, cv2.IMREAD_COLOR), dsize=(256, 256),\n",
        "                                 interpolation=cv2.INTER_LINEAR).astype(np.float64) for file in files]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YoqgOQ91WL7z"
      },
      "outputs": [],
      "source": [
        "# make training img label\n",
        "image_num = train_img.shape[0]\n",
        "labels = 4\n",
        "train_label = np.array(list(chain.from_iterable((repeat(n, k) for (n, k) in zip(range(labels), each_class_num)))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VplUw2wA2v2b"
      },
      "outputs": [],
      "source": [
        "# normalize\n",
        "train_img = train_img / (256.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZgOhCJ3kzqW7"
      },
      "outputs": [],
      "source": [
        "# split data set\n",
        "x_train, x_test, y_train, y_test = train_test_split(train_img, train_label, test_size=0.1, stratify=train_label, random_state=34)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, stratify=y_train, random_state=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fonqlP-7Oat"
      },
      "source": [
        "# Model Architecture\n",
        "\n",
        "기본적으로 ResNet의 구조를 가지고 있는 NN으로 구성\n",
        "## Hyperparameters\n",
        "##### **수정 불가능한 hyperparameter**\n",
        "  - input_img_shape : 256*256으로 고정\n",
        "  - input_channel : RGB 3채널 이미지\n",
        "\n",
        "##### **수정 가능한 hyperparmeter**\n",
        "  - layer1_output_channel : layer1 의 output channel개수\n",
        "  - layer1_kernel_size : ResNet 처음 conv kernel_size는 7*7 이용\n",
        "  - layer2_output_channel : layer2 의 output channel개수 (== layer1_output_channel)\n",
        "  - layer3_output_channel : layer3 의 output channel개수 (layer2_output_channel * 2)\n",
        "  - res_kernel_size : resNet에서는 기본적으로 첫번째 conv 제외 3*3 kernel로 고정\n",
        "\n",
        "## Layers\n",
        "1. layer1 : convolution + pooling\n",
        "2. layer2 : conv + norm + relu + conv + norm + relu + add (1 residual unit)\n",
        "3. layer3 : conv + norm + relu + conv + norm + relu + identity + add (1 residual unit)\n",
        "4. flatten : 분류기에 넣기 위해 flatten진행\n",
        "5. classifier : 분류기, FC layer이용, ResNet에서는 FC layer의 Weight개수가 많으므로 한개의 FC layer만 사용\n",
        "\n",
        "### 1*1 Convolution\n",
        "layer2에서 사용하는 res_unit2의 경우, 이미지 데이터가 들어갈 때 layer2_output_channel개로 들어가지만, 나올 때 layer3_output_channel로 나오게 되는데, channel개수를 맞추어주기 위해서 convolution진행.\n",
        "이미지 크기도 res_unit2의 첫번째 convolution에서 stride (2, 2)로 진행하므로 반으로 줄어들게 되므로 1*1 convolution도 stride (2, 2)로 진행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "83CKVEPeR1TD"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "global input_img_shape, input_channel, layer1_output_channel, layer1_kernel_size, res_kernel_size, layer2_output_channel, layer3_output_channel\n",
        "input_img_shape = (256, 256, 3)\n",
        "input_channel = 3\n",
        "layer1_output_channel = 6\n",
        "layer1_kernel_size = (7, 7)\n",
        "layer2_output_channel = 6\n",
        "layer3_output_channel = 12\n",
        "res_kernel_size = (11, 11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "892Gl70xF178"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.keras.activations import softmax\n",
        "class cnn_model(tf.keras.Model):\n",
        "  global input_img_shape, input_channel, layer1_output_channel, layer1_kernel_size, res_kernel_size, layer2_output_channel, layer3_output_channel\n",
        "  def __init__(self):\n",
        "    super(cnn_model, self).__init__()\n",
        "    \n",
        "    self.conv1 = layers.Conv2D(layer1_output_channel, layer1_kernel_size, strides=(2, 2), \n",
        "                       padding='same', input_shape=input_img_shape, activation='relu')\n",
        "    self.pool1 = layers.MaxPool2D(pool_size=(4, 4))\n",
        "    self.conv2_t = layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same')\n",
        "    self.batchnorm1 = layers.BatchNormalization()\n",
        "    self.relu1 = layers.ReLU()\n",
        "    self.conv2 = layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same')\n",
        "    self.batchnorm2 = layers.BatchNormalization()\n",
        "    self.relu2 = layers.ReLU()\n",
        "    self.add1 = layers.Add()\n",
        "    \n",
        "    self.conv3 = layers.Conv2D(layer3_output_channel, res_kernel_size, strides=(2, 2), padding='same')\n",
        "    self.batchnorm3 = layers.BatchNormalization()\n",
        "    self.relu3 = layers.ReLU()\n",
        "    \n",
        "    self.conv4 = layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same')\n",
        "    self.batchnorm4 = layers.BatchNormalization()\n",
        "    self.relu4 = layers.ReLU()\n",
        "    self.identity = layers.Conv2D(layer3_output_channel, (1, 1), padding='same', strides=(2, 2))\n",
        "    self.add2 = layers.Add()\n",
        "    \n",
        "    self.flat = layers.Flatten()\n",
        "    self.fc1 = layers.Dense(4)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.pool1(x)\n",
        "    x_t = self.conv2_t(x)\n",
        "    x_t = self.batchnorm1(x_t)\n",
        "    x_t = self.relu1(x_t)\n",
        "    x_t = self.conv2(x_t)\n",
        "    x_t = self.batchnorm2(x_t)\n",
        "    x_t = self.relu2(x_t)\n",
        "    x = self.add1([x, x_t])\n",
        "\n",
        "    x_t = self.conv3(x)\n",
        "    x_t = self.batchnorm3(x_t)\n",
        "    x_t = self.relu3(x_t)\n",
        "    x_t = self.conv4(x_t)\n",
        "    x_t = self.batchnorm4(x_t)\n",
        "    x_t = self.relu4(x_t)\n",
        "    x = self.identity(x)\n",
        "    x = self.add2([x, x_t])\n",
        "    x = self.flat(x)\n",
        "    x = self.fc1(x)\n",
        "    probs = softmax(x)\n",
        "    return probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "m_F-B1R6A2g8"
      },
      "outputs": [],
      "source": [
        "model = cnn_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct65qbqsyrX9"
      },
      "source": [
        "#model optimizer, loss등 정의 compile\n",
        "\n",
        "optimizer : adam\n",
        "\n",
        "loss : sparse categorical crossentropy\n",
        "- 3개 이상의 class로 나누기 때문에 categorical crossentropy를 사용하고, \n",
        "- 마지막 classifier에서 softmax로 activation 함수를 사용하기 때문에 sparse categorical crossentropy loss에서 자체적으로 one-hot진행하도록 함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "L8gudp5MT9Y7"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT8fbjD4yxjs"
      },
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "v6KAI2UG4gl8"
      },
      "outputs": [],
      "source": [
        "# Train Hyperparameters\n",
        "epoch = 50\n",
        "batch = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kYyYZywR5vYQ"
      },
      "outputs": [],
      "source": [
        "# checkpoint, earlystopping\n",
        "filename = 'checkpoint.ckpt'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "earlystopping = EarlyStopping(monitor='val_loss', patience=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZXKBeRnUNTu",
        "outputId": "7f03c855-f666-4929-f615-52c7fb3c44e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 1.3388 - accuracy: 0.5513\n",
            "Epoch 00001: val_loss improved from inf to 1.38467, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 14s 113ms/step - loss: 1.3388 - accuracy: 0.5513 - val_loss: 1.3847 - val_accuracy: 0.2836\n",
            "Epoch 2/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.5363 - accuracy: 0.8269\n",
            "Epoch 00002: val_loss did not improve from 1.38467\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.5363 - accuracy: 0.8269 - val_loss: 1.3891 - val_accuracy: 0.2537\n",
            "Epoch 3/50\n",
            "18/19 [===========================>..] - ETA: 0s - loss: 0.4047 - accuracy: 0.8715\n",
            "Epoch 00003: val_loss did not improve from 1.38467\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 0.4152 - accuracy: 0.8706 - val_loss: 1.4027 - val_accuracy: 0.2836\n",
            "Epoch 4/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.3814 - accuracy: 0.8571\n",
            "Epoch 00004: val_loss improved from 1.38467 to 1.32475, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 46ms/step - loss: 0.3814 - accuracy: 0.8571 - val_loss: 1.3248 - val_accuracy: 0.2985\n",
            "Epoch 5/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.2190 - accuracy: 0.9227\n",
            "Epoch 00005: val_loss did not improve from 1.32475\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 0.2190 - accuracy: 0.9227 - val_loss: 1.3536 - val_accuracy: 0.2388\n",
            "Epoch 6/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.3342 - accuracy: 0.8857\n",
            "Epoch 00006: val_loss did not improve from 1.32475\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.3342 - accuracy: 0.8857 - val_loss: 1.6377 - val_accuracy: 0.2239\n",
            "Epoch 7/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.1948 - accuracy: 0.9412\n",
            "Epoch 00007: val_loss did not improve from 1.32475\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.1948 - accuracy: 0.9412 - val_loss: 1.5042 - val_accuracy: 0.4627\n",
            "Epoch 8/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.1220 - accuracy: 0.9613\n",
            "Epoch 00008: val_loss did not improve from 1.32475\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 0.1220 - accuracy: 0.9613 - val_loss: 1.5702 - val_accuracy: 0.3134\n",
            "Epoch 9/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.1199 - accuracy: 0.9580\n",
            "Epoch 00009: val_loss improved from 1.32475 to 1.12561, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 47ms/step - loss: 0.1199 - accuracy: 0.9580 - val_loss: 1.1256 - val_accuracy: 0.4179\n",
            "Epoch 10/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0664 - accuracy: 0.9832\n",
            "Epoch 00010: val_loss did not improve from 1.12561\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.0664 - accuracy: 0.9832 - val_loss: 1.5135 - val_accuracy: 0.4627\n",
            "Epoch 11/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9933\n",
            "Epoch 00011: val_loss did not improve from 1.12561\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.0350 - accuracy: 0.9933 - val_loss: 1.5124 - val_accuracy: 0.4925\n",
            "Epoch 12/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 0.9899\n",
            "Epoch 00012: val_loss did not improve from 1.12561\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.0335 - accuracy: 0.9899 - val_loss: 1.1934 - val_accuracy: 0.5672\n",
            "Epoch 13/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9933\n",
            "Epoch 00013: val_loss did not improve from 1.12561\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 1.1533 - val_accuracy: 0.5224\n",
            "Epoch 14/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9983\n",
            "Epoch 00014: val_loss did not improve from 1.12561\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 0.0123 - accuracy: 0.9983 - val_loss: 1.2618 - val_accuracy: 0.4925\n",
            "Epoch 15/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9983\n",
            "Epoch 00015: val_loss improved from 1.12561 to 0.98228, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.0113 - accuracy: 0.9983 - val_loss: 0.9823 - val_accuracy: 0.6418\n",
            "Epoch 16/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 00016: val_loss improved from 0.98228 to 0.57870, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 46ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.5787 - val_accuracy: 0.7761\n",
            "Epoch 17/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 1.0000\n",
            "Epoch 00017: val_loss did not improve from 0.57870\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.8531 - val_accuracy: 0.7164\n",
            "Epoch 18/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 00018: val_loss did not improve from 0.57870\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6263 - val_accuracy: 0.7612\n",
            "Epoch 19/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 00019: val_loss improved from 0.57870 to 0.40631, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 47ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4063 - val_accuracy: 0.8358\n",
            "Epoch 20/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 00020: val_loss did not improve from 0.40631\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5239 - val_accuracy: 0.8060\n",
            "Epoch 21/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 00021: val_loss improved from 0.40631 to 0.34199, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 44ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.8209\n",
            "Epoch 22/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 00022: val_loss did not improve from 0.34199\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4026 - val_accuracy: 0.8209\n",
            "Epoch 23/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 00023: val_loss did not improve from 0.34199\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3523 - val_accuracy: 0.8507\n",
            "Epoch 24/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 00024: val_loss improved from 0.34199 to 0.32893, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 46ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3289 - val_accuracy: 0.8657\n",
            "Epoch 25/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 9.0859e-04 - accuracy: 1.0000\n",
            "Epoch 00025: val_loss improved from 0.32893 to 0.25928, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 46ms/step - loss: 9.0859e-04 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.8955\n",
            "Epoch 26/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 8.7445e-04 - accuracy: 1.0000\n",
            "Epoch 00026: val_loss improved from 0.25928 to 0.23690, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 47ms/step - loss: 8.7445e-04 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.8955\n",
            "Epoch 27/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 9.1429e-04 - accuracy: 1.0000\n",
            "Epoch 00027: val_loss improved from 0.23690 to 0.21439, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 47ms/step - loss: 9.1429e-04 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9254\n",
            "Epoch 28/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 8.9283e-04 - accuracy: 1.0000\n",
            "Epoch 00028: val_loss improved from 0.21439 to 0.21293, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 46ms/step - loss: 8.9283e-04 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9254\n",
            "Epoch 29/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 00029: val_loss improved from 0.21293 to 0.17820, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 45ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9403\n",
            "Epoch 30/50\n",
            "18/19 [===========================>..] - ETA: 0s - loss: 8.8011e-04 - accuracy: 1.0000\n",
            "Epoch 00030: val_loss improved from 0.17820 to 0.15175, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 60ms/step - loss: 8.9408e-04 - accuracy: 1.0000 - val_loss: 0.1517 - val_accuracy: 0.9552\n",
            "Epoch 31/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 7.0959e-04 - accuracy: 1.0000\n",
            "Epoch 00031: val_loss did not improve from 0.15175\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 7.0959e-04 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9403\n",
            "Epoch 32/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 6.0912e-04 - accuracy: 1.0000\n",
            "Epoch 00032: val_loss did not improve from 0.15175\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 6.0912e-04 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9552\n",
            "Epoch 33/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 6.7094e-04 - accuracy: 1.0000\n",
            "Epoch 00033: val_loss did not improve from 0.15175\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 6.7094e-04 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9403\n",
            "Epoch 34/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 5.5602e-04 - accuracy: 1.0000\n",
            "Epoch 00034: val_loss did not improve from 0.15175\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 5.5602e-04 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9403\n",
            "Epoch 35/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 5.3506e-04 - accuracy: 1.0000\n",
            "Epoch 00035: val_loss did not improve from 0.15175\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 5.3506e-04 - accuracy: 1.0000 - val_loss: 0.1655 - val_accuracy: 0.9254\n",
            "Epoch 36/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 5.0324e-04 - accuracy: 1.0000\n",
            "Epoch 00036: val_loss did not improve from 0.15175\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 5.0324e-04 - accuracy: 1.0000 - val_loss: 0.1522 - val_accuracy: 0.9254\n",
            "Epoch 37/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 5.0001e-04 - accuracy: 1.0000\n",
            "Epoch 00037: val_loss did not improve from 0.15175\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 5.0001e-04 - accuracy: 1.0000 - val_loss: 0.1642 - val_accuracy: 0.9403\n",
            "Epoch 38/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 4.6707e-04 - accuracy: 1.0000\n",
            "Epoch 00038: val_loss did not improve from 0.15175\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 4.6707e-04 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 0.9403\n",
            "Epoch 39/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 4.7555e-04 - accuracy: 1.0000\n",
            "Epoch 00039: val_loss did not improve from 0.15175\n",
            "19/19 [==============================] - 1s 42ms/step - loss: 4.7555e-04 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9403\n",
            "Epoch 40/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 6.2947e-04 - accuracy: 1.0000\n",
            "Epoch 00040: val_loss did not improve from 0.15175\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 6.2947e-04 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 0.9254\n",
            "Epoch 41/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 6.5307e-04 - accuracy: 1.0000\n",
            "Epoch 00041: val_loss did not improve from 0.15175\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 6.5307e-04 - accuracy: 1.0000 - val_loss: 0.1692 - val_accuracy: 0.9254\n",
            "Epoch 42/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 5.7764e-04 - accuracy: 1.0000\n",
            "Epoch 00042: val_loss did not improve from 0.15175\n",
            "19/19 [==============================] - 1s 42ms/step - loss: 5.7764e-04 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9403\n",
            "Epoch 43/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 3.8239e-04 - accuracy: 1.0000\n",
            "Epoch 00043: val_loss did not improve from 0.15175\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 3.8239e-04 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 0.9403\n",
            "Epoch 44/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 3.8472e-04 - accuracy: 1.0000\n",
            "Epoch 00044: val_loss did not improve from 0.15175\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 3.8472e-04 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 0.9254\n",
            "Epoch 45/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 4.2183e-04 - accuracy: 1.0000\n",
            "Epoch 00045: val_loss did not improve from 0.15175\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 4.2183e-04 - accuracy: 1.0000 - val_loss: 0.1616 - val_accuracy: 0.9254\n",
            "Epoch 46/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 4.5983e-04 - accuracy: 1.0000\n",
            "Epoch 00046: val_loss did not improve from 0.15175\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 4.5983e-04 - accuracy: 1.0000 - val_loss: 0.1622 - val_accuracy: 0.9403\n",
            "Epoch 47/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 4.7983e-04 - accuracy: 1.0000\n",
            "Epoch 00047: val_loss improved from 0.15175 to 0.14557, saving model to checkpoint.ckpt\n",
            "19/19 [==============================] - 1s 46ms/step - loss: 4.7983e-04 - accuracy: 1.0000 - val_loss: 0.1456 - val_accuracy: 0.9403\n",
            "Epoch 48/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 3.3078e-04 - accuracy: 1.0000\n",
            "Epoch 00048: val_loss did not improve from 0.14557\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 3.3078e-04 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9254\n",
            "Epoch 49/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 4.1951e-04 - accuracy: 1.0000\n",
            "Epoch 00049: val_loss did not improve from 0.14557\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 4.1951e-04 - accuracy: 1.0000 - val_loss: 0.1653 - val_accuracy: 0.9403\n",
            "Epoch 50/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 3.0535e-04 - accuracy: 1.0000\n",
            "Epoch 00050: val_loss did not improve from 0.14557\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 3.0535e-04 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9254\n"
          ]
        }
      ],
      "source": [
        "# Train\n",
        "history = model.fit(x_train, y_train, epochs=epoch, validation_data=(x_val, y_val) , callbacks=[checkpoint, earlystopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BKGxiqTMe2Se"
      },
      "outputs": [],
      "source": [
        "# load best model from checkpoints\n",
        "model_fi = cnn_model()\n",
        "model_fi.load_weights(filename)\n",
        "model_fi.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Wct1WJOD4uOW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4e1b7db-740a-4f72-a526-1c56e1a6fb95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 1s 62ms/step - loss: 0.1767 - accuracy: 0.9324\n"
          ]
        }
      ],
      "source": [
        "# evaluate model using test data\n",
        "results = model_fi.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGT-cZKhBqvQ",
        "outputId": "efad8e33-7498-421b-bc87-bf689c2f042c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"cnn_model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           multiple                  888       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  multiple                 0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           multiple                  4362      \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  multiple                 24        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_4 (ReLU)              multiple                  0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           multiple                  4362      \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  multiple                 24        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_5 (ReLU)              multiple                  0         \n",
            "                                                                 \n",
            " add_2 (Add)                 multiple                  0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           multiple                  8724      \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  multiple                 48        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_6 (ReLU)              multiple                  0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          multiple                  17436     \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  multiple                 48        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_7 (ReLU)              multiple                  0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          multiple                  84        \n",
            "                                                                 \n",
            " add_3 (Add)                 multiple                  0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         multiple                  0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             multiple                  12292     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 48,292\n",
            "Trainable params: 48,220\n",
            "Non-trainable params: 72\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# model summary\n",
        "model_fi.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWOqab0csQye"
      },
      "outputs": [],
      "source": [
        "# save current model\n",
        "model_fi.save('cnnmodel')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}