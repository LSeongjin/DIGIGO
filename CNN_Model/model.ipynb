{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Module Import\n",
        "## Module\n",
        "\n",
        "\n",
        "* numpy : ndarray\n",
        "* cv2 : image resize, 불러오기 등의 처리\n",
        "* glob : 디렉토리 파일 탐색\n",
        "* tensorflow : 모듈 설계\n",
        "* itertools : list iterate"
      ],
      "metadata": {
        "id": "_S3m2Ayl54DA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oxye4JV62b0C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import sys\n",
        "import os\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from itertools import chain, repeat, cycle\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Colab 드라이브 마운트\n",
        "##### 이후 $ cd gdrive/MyDrive/경로.. 로 기본 디렉토리 수정하여 사용\n",
        "##### 이미지 데이터를 가지고 와서 train data 라벨링 진행해야 함"
      ],
      "metadata": {
        "id": "cIeEwiRv6PfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ct7XkwXg3Q35",
        "outputId": "739eb2b4-f11f-4df4-b91a-e86bb8ad5910"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd gdrive/MyDrive/KT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUerRhDF4Vyv",
        "outputId": "63f00fda-ca0b-43ff-e0ac-ca603208fb5d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/KT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 이미지 불러오기\n",
        "##### glob.glob(path) 함수 결과를 sort하여 img데이터 들어오는 순서 고정\n",
        "##### cv2.imread() 함수로 img를 읽어오게 됨\n",
        "  - cv2.IMREAD_COLOR : 컬러 이미지 불러올 때 쓰는 옵션\n",
        "##### cv2.resize() : 크기 조절\n",
        "  - dsize를 고정함으로써 원하는 크기로 불러온 이미지 데이터 수정 가능\n",
        "\n",
        "##### 256.0으로 나누어 float데이터 타입을 유지하면서 normalize\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aaobow4Z6aq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get img list from path\n",
        "image_folders = sorted(glob.glob(\"Image/*\"))"
      ],
      "metadata": {
        "id": "dk5R2eBZ2q25"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = []\n",
        "each_class_num = []\n",
        "for folder in image_folders:\n",
        "  temp = sorted(glob.glob(folder + \"/*\"))\n",
        "  files.extend(temp)\n",
        "  each_class_num.append(len(temp))"
      ],
      "metadata": {
        "id": "ceGn9zm94pFi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "each_class_num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g7qW0KW2tJE",
        "outputId": "19b5da86-0626-4579-9f01-79f2028fb6d3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[60, 50, 50, 50]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read image from files list & reshape\n",
        "# train_img shape : ( , 256, 256, 3)\n",
        "train_img = np.array(np.array([cv2.resize(cv2.imread(file, cv2.IMREAD_COLOR), dsize=(256, 256),\n",
        "                                 interpolation=cv2.INTER_LINEAR).astype(np.float64) for file in files]))"
      ],
      "metadata": {
        "id": "A9AX9HYa2tFU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_num = train_img.shape[0]\n",
        "labels = 4\n",
        "train_label = np.array(list(chain.from_iterable((repeat(n, k) for (n, k) in zip(range(labels), each_class_num)))))"
      ],
      "metadata": {
        "id": "YoqgOQ91WL7z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_img.shape)\n",
        "print(train_img[0].shape)\n",
        "print(train_label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpEZlnkQ2uiU",
        "outputId": "21eaec12-04cd-4172-e21b-323a4aed6bc5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(210, 256, 256, 3)\n",
            "(256, 256, 3)\n",
            "(210,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize\n",
        "train_img = train_img / (256.0)"
      ],
      "metadata": {
        "id": "VplUw2wA2v2b"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(train_img, train_label, test_size=0.1, stratify=train_label, random_state=34)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=12)"
      ],
      "metadata": {
        "id": "ZgOhCJ3kzqW7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTRfdCxD35zX",
        "outputId": "a4d06d31-5239-4302-e054-f04e7b6fdab5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(151, 256, 256, 3)\n",
            "(151,)\n",
            "(21, 256, 256, 3)\n",
            "(21,)\n",
            "(38, 256, 256, 3)\n",
            "(38,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture\n",
        "\n",
        "**코드가 조금 더러움 주의**\n",
        "\n",
        "기본적으로 ResNet의 구조를 가지고 있는 NN으로 구성\n",
        "## Hyperparameters\n",
        "##### **수정 불가능한 hyperparameter**\n",
        "  - input_img_shape : 256*256으로 고정\n",
        "  - input_channel : RGB 3채널 이미지\n",
        "\n",
        "##### **수정 가능한 hyperparmeter**\n",
        "  - layer1_output_channel : layer1 의 output channel개수\n",
        "  - layer1_kernel_size : ResNet 처음 conv kernel_size는 7*7 이용\n",
        "  - layer2_output_channel : layer2 의 output channel개수 (== layer1_output_channel)\n",
        "  - layer3_output_channel : layer3 의 output channel개수 (layer2_output_channel * 2)\n",
        "  - res_kernel_size : resNet에서는 기본적으로 첫번째 conv 제외 3*3 kernel로 고정\n",
        "\n",
        "## Layers\n",
        "1. layer1 : 7*7 convolution + pooling\n",
        "2. layer2 : res_unit1 * 3\n",
        "3. layer3 : res_unit2 + res_unit3 * 3\n",
        "4. flatten : 분류기에 넣기 위해 flatten진행\n",
        "5. classifier : 분류기, FC layer이용, ResNet에서는 FC layer의 Weight개수가 많으므로 한개의 FC layer만 사용\n",
        "\n",
        "### 1*1 Convolution\n",
        "layer2에서 사용하는 res_unit2의 경우, 이미지 데이터가 들어갈 때 layer2_output_channel개로 들어가지만, 나올 때 layer3_output_channel로 나오게 되는데, channel개수를 맞추어주기 위해서 convolution진행.\n",
        "이미지 크기도 res_unit2의 첫번째 convolution에서 stride (2, 2)로 진행하므로 반으로 줄어들게 되므로 1*1 convolution도 stride (2, 2)로 진행"
      ],
      "metadata": {
        "id": "9fonqlP-7Oat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "global input_img_shape, input_channel, layer1_output_channel, layer1_kernel_size, res_kernel_size, layer2_output_channel, layer3_output_channel\n",
        "input_img_shape = (256, 256, 3)\n",
        "input_channel = 3\n",
        "layer1_output_channel = 12\n",
        "layer1_kernel_size = (7, 7)\n",
        "layer2_output_channel = 12\n",
        "layer3_output_channel = 24\n",
        "\n",
        "# overall residual units num = num_residual_units * num_residual_layers \n",
        "res_kernel_size = (3, 3)"
      ],
      "metadata": {
        "id": "83CKVEPeR1TD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.activations import softmax\n",
        "class cnn_model(tf.keras.Model):\n",
        "  global input_img_shape, input_channel, layer1_output_channel, layer1_kernel_size, res_kernel_size, layer2_output_channel, layer3_output_channel\n",
        "  def __init__(self):\n",
        "    super(cnn_model, self).__init__()\n",
        "    self.num_residual_units = 3 # number of units per layer\n",
        "    self.num_residual_layers = 2 # number of layer per model\n",
        "    self.res_kernel_size = (3, 3)\n",
        "\n",
        "    self.layer1 = models.Sequential(\n",
        "        [layers.Conv2D(layer1_output_channel, layer1_kernel_size, strides=(2, 2), \n",
        "                       padding='same', input_shape=input_img_shape, activation='relu'),\n",
        "         layers.MaxPool2D(pool_size=(2, 2))]\n",
        "    )\n",
        "\n",
        "    self.res_unit1 = models.Sequential(\n",
        "        [layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    self.res_unit2 = models.Sequential(\n",
        "        [layers.Conv2D(layer3_output_channel, res_kernel_size, strides=(2, 2), padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    self.res_unit3 = models.Sequential(\n",
        "        [layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    self.identity = layers.Conv2D(layer3_output_channel, (1, 1), padding='same', strides=(2, 2))\n",
        "\n",
        "    self.flatten_layer = layers.Flatten()\n",
        "\n",
        "    self.classifier = models.Sequential(\n",
        "        [layers.Dense(4)]\n",
        "    )\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x_t = self.res_unit1(x)\n",
        "    x = x + x_t\n",
        "    #x_t = self.res_unit1(x)\n",
        "    #x = x + x_t\n",
        "    #x_t = self.res_unit1(x)\n",
        "    #x = x + x_t\n",
        "    x_t = self.res_unit2(x)\n",
        "    x = self.identity(x) + x_t\n",
        "    x_t = self.res_unit3(x)\n",
        "    x = x + x_t\n",
        "    #x_t = self.res_unit3(x)\n",
        "    #x = x + x_t\n",
        "    #x_t = self.res_unit3(x)\n",
        "    #x = x + x_t\n",
        "    x = self.flatten_layer(x)\n",
        "    x = self.classifier(x)\n",
        "    probs = softmax(x)\n",
        "    return probs"
      ],
      "metadata": {
        "id": "w-0NYFJ_O4lk"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = cnn_model()"
      ],
      "metadata": {
        "id": "m_F-B1R6A2g8"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model optimizer, loss등 정의 compile"
      ],
      "metadata": {
        "id": "Ct65qbqsyrX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "L8gudp5MT9Y7"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "sT8fbjD4yxjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Hyperparameters\n",
        "epoch = 50\n",
        "batch = 10"
      ],
      "metadata": {
        "id": "v6KAI2UG4gl8"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEFStN575NmW",
        "outputId": "482e2b31-63b1-4ea1-b1d4-03124bd4fb52"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(151, 256, 256, 3)\n",
            "(151,)\n",
            "(21, 256, 256, 3)\n",
            "(21,)\n",
            "(38, 256, 256, 3)\n",
            "(38,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.sum())\n",
        "print(y_test.sum())\n",
        "print(y_val.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNe23JnU5XVg",
        "outputId": "cd614339-e901-4da2-f22b-36ec6293fede"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "216\n",
            "30\n",
            "54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=epoch, batch_size=batch, validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZXKBeRnUNTu",
        "outputId": "728705f7-a957-4751-97f6-5c28cab9c791"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.2465 - accuracy: 0.9603 - val_loss: 6.0560 - val_accuracy: 0.3158\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.1896 - accuracy: 0.9536 - val_loss: 7.5526 - val_accuracy: 0.3947\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 0.2506 - accuracy: 0.9735 - val_loss: 4.3233 - val_accuracy: 0.4211\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.0244 - accuracy: 0.9934 - val_loss: 7.6582 - val_accuracy: 0.4474\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 29ms/step - loss: 0.0290 - accuracy: 0.9934 - val_loss: 13.0627 - val_accuracy: 0.2368\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 1.7665 - accuracy: 0.8013 - val_loss: 16.5037 - val_accuracy: 0.3421\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 2.2162 - accuracy: 0.8675 - val_loss: 7.4377 - val_accuracy: 0.4737\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 1.0135 - accuracy: 0.9205 - val_loss: 7.4283 - val_accuracy: 0.4474\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.7438 - accuracy: 0.9272 - val_loss: 6.5905 - val_accuracy: 0.5526\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 0.2929 - accuracy: 0.9470 - val_loss: 8.3241 - val_accuracy: 0.5263\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.1479 - accuracy: 0.9669 - val_loss: 3.4153 - val_accuracy: 0.6316\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 0.0740 - accuracy: 0.9801 - val_loss: 2.2726 - val_accuracy: 0.7632\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0199 - accuracy: 0.9934 - val_loss: 2.2339 - val_accuracy: 0.7632\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 6.5142e-05 - accuracy: 1.0000 - val_loss: 2.8930 - val_accuracy: 0.7105\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 4.9525e-06 - accuracy: 1.0000 - val_loss: 2.9503 - val_accuracy: 0.7105\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 1.6586e-05 - accuracy: 1.0000 - val_loss: 2.8854 - val_accuracy: 0.7105\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 1.4017e-04 - accuracy: 1.0000 - val_loss: 2.7712 - val_accuracy: 0.7368\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 5.9695e-05 - accuracy: 1.0000 - val_loss: 2.6694 - val_accuracy: 0.7368\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 7.4726e-05 - accuracy: 1.0000 - val_loss: 2.5662 - val_accuracy: 0.7632\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0120 - accuracy: 0.9934 - val_loss: 2.3619 - val_accuracy: 0.7632\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 8.8296e-06 - accuracy: 1.0000 - val_loss: 2.2021 - val_accuracy: 0.7632\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 3.9847e-06 - accuracy: 1.0000 - val_loss: 2.0930 - val_accuracy: 0.7632\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0149 - val_accuracy: 0.7895\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 6.8366e-07 - accuracy: 1.0000 - val_loss: 1.9130 - val_accuracy: 0.7895\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 1.0934e-06 - accuracy: 1.0000 - val_loss: 1.8541 - val_accuracy: 0.8158\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.4078e-07 - accuracy: 1.0000 - val_loss: 1.8127 - val_accuracy: 0.8421\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 3.7288e-06 - accuracy: 1.0000 - val_loss: 1.7782 - val_accuracy: 0.8684\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 8.9761e-07 - accuracy: 1.0000 - val_loss: 1.7678 - val_accuracy: 0.8684\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 1.2708e-04 - accuracy: 1.0000 - val_loss: 1.7536 - val_accuracy: 0.8684\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.5722e-06 - accuracy: 1.0000 - val_loss: 1.7393 - val_accuracy: 0.8684\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 5.8623e-06 - accuracy: 1.0000 - val_loss: 1.7323 - val_accuracy: 0.8684\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 4.1210e-07 - accuracy: 1.0000 - val_loss: 1.7360 - val_accuracy: 0.8684\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 7.0104e-07 - accuracy: 1.0000 - val_loss: 1.7367 - val_accuracy: 0.8684\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 2.3554e-05 - accuracy: 1.0000 - val_loss: 1.7306 - val_accuracy: 0.8684\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 3.5125e-06 - accuracy: 1.0000 - val_loss: 1.7216 - val_accuracy: 0.8684\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 8.4235e-07 - accuracy: 1.0000 - val_loss: 1.7223 - val_accuracy: 0.8684\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 1.8504e-06 - accuracy: 1.0000 - val_loss: 1.7223 - val_accuracy: 0.8684\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 6.2130e-07 - accuracy: 1.0000 - val_loss: 1.7206 - val_accuracy: 0.8684\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 1.0630e-05 - accuracy: 1.0000 - val_loss: 1.7283 - val_accuracy: 0.8684\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 1.8670e-06 - accuracy: 1.0000 - val_loss: 1.7236 - val_accuracy: 0.8684\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 1.0618e-06 - accuracy: 1.0000 - val_loss: 1.7214 - val_accuracy: 0.8684\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.0277e-05 - accuracy: 1.0000 - val_loss: 1.7233 - val_accuracy: 0.8684\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 6.2130e-07 - accuracy: 1.0000 - val_loss: 1.7172 - val_accuracy: 0.8684\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 8.1479e-05 - accuracy: 1.0000 - val_loss: 1.7220 - val_accuracy: 0.8684\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 5.9998e-07 - accuracy: 1.0000 - val_loss: 1.7237 - val_accuracy: 0.8684\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 8.2506e-05 - accuracy: 1.0000 - val_loss: 1.7235 - val_accuracy: 0.8684\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.1631e-07 - accuracy: 1.0000 - val_loss: 1.7173 - val_accuracy: 0.8684\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 5.8972e-07 - accuracy: 1.0000 - val_loss: 1.7183 - val_accuracy: 0.8684\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 3.2346e-06 - accuracy: 1.0000 - val_loss: 1.7255 - val_accuracy: 0.8684\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 1.0642e-06 - accuracy: 1.0000 - val_loss: 1.7358 - val_accuracy: 0.8684\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7d53d1dd50>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(x_test, y_test, batch_size=batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wct1WJOD4uOW",
        "outputId": "06862986-7f97-4ab3-e423-1572d5711d57"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 9ms/step - loss: 2.2790 - accuracy: 0.8095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('test loss, test acc:', results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuHBsYsk40Qt",
        "outputId": "da22e985-2116-4d22-d768-7888de174e31"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss, test acc: [10.218592643737793, 0.2857142984867096]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGT-cZKhBqvQ",
        "outputId": "d13d7378-87df-40e3-e906-4e16542d5a94"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"cnn_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential (Sequential)     (None, 64, 64, 12)        1776      \n",
            "                                                                 \n",
            " sequential_1 (Sequential)   (None, 64, 64, 12)        2712      \n",
            "                                                                 \n",
            " sequential_2 (Sequential)   (None, 32, 32, 24)        8016      \n",
            "                                                                 \n",
            " sequential_3 (Sequential)   (None, 32, 32, 24)        10608     \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           multiple                  312       \n",
            "                                                                 \n",
            " flatten (Flatten)           multiple                  0         \n",
            "                                                                 \n",
            " sequential_4 (Sequential)   (None, 4)                 98308     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,732\n",
            "Trainable params: 121,492\n",
            "Non-trainable params: 240\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dump"
      ],
      "metadata": {
        "id": "lwMfA7Rdyzm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model(train_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xU5fCSjdBkgP",
        "outputId": "9dfb537b-e7c6-4d19-99a2-f07530c98635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 64, 64, 12)\n",
            "(4, 64, 64, 12)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
              "array([[0.01513817, 0.87859064, 0.00146113, 0.10481004],\n",
              "       [0.02088634, 0.9301859 , 0.00163644, 0.04729134],\n",
              "       [0.05060832, 0.80482614, 0.00253833, 0.14202717],\n",
              "       [0.01934402, 0.88991696, 0.00185118, 0.08888792]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def residual_unit(self, x, in_channel, out_channel, kernel_size):\n",
        "  #   if in_channel == out_channel:\n",
        "  #     res1 = layers.Conv2D(out_channel, kernel_size, padding='same', strides=(1, 1))\n",
        "  #   else:\n",
        "  #     res1 = layers.Conv2D(out_channel, kernel_size, padding='same', strides=(2, 2))\n",
        "  #   batch1 = layers.BatchNormalization()\n",
        "  #   relu1 = layers.ReLU()\n",
        "  #   res2 = layers.Conv2D(out_channel, kernel_size, padding='same')\n",
        "  #   batch2 = layers.BatchNormalization()\n",
        "  #   relu2 = layers.ReLU()\n",
        "\n",
        "  #   x_t = res1(x)\n",
        "  #   x_t = batch1(x_t)\n",
        "  #   x_t = relu1(x_t)\n",
        "  #   x_t = res2(x_t)\n",
        "  #   x_t = batch2(x_t)\n",
        "  #   x_t = relu2(x_t)\n",
        "\n",
        "  #   if in_channel != out_channel:\n",
        "  #     identity = layers.Conv2D(out_channel, (1, 1), padding='same', strides=(2, 2))\n",
        "  #     x = identity(x)\n",
        "  #   print(x_t.shape)\n",
        "  #   print(x.shape)\n",
        "  #   return x_t + x\n",
        "\n",
        "  # channels = x.shape[3]\n",
        "    # for l in range(self.num_residual_layers):\n",
        "    #   for u in range(self.num_residual_units):\n",
        "    #     x = self.residual_unit(x, channels, (lambda x,y:channels*2 if x != 0 and y == 0 else channels)(l, u), self.res_kernel_size)\n",
        "    #     channels = channels * 2 if l != 0 and u == 0 else channels"
      ],
      "metadata": {
        "id": "MMhj8WxlrPaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape = (256, 256, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
      ],
      "metadata": {
        "id": "MYpwDLKG2xdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "5xgtV31q2yz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model information\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "4zYxbpLf2z_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "#print(model(train_img))"
      ],
      "metadata": {
        "id": "IZ_O3u7E21Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in_channel : input image channel size, out_channel : output image channel of each unit\n",
        "# kernel_size  ex) (3, 3), (5, 5), ..\n",
        "class ResidualUnit(tf.keras.Model):\n",
        "  def __init__(self, in_channel, out_channel, kernel_size, stride=False):\n",
        "    super(ResidualUnit, self).__init__()\n",
        "    if stride:\n",
        "      self.conv1 = layers.Conv2D(out_channel, kernel_size, padding='same', activation='relu', stride=(2, 2))\n",
        "    else:\n",
        "      self.conv1 = layers.Conv2D(out_channel, kernel_size, padding='same', activation='relu')\n",
        "    self.conv2 = layers.Conv2D(out_channel, kernel_size, padding='same', activation='relu')\n",
        "\n",
        "    if in_channel ==  out_channel:\n",
        "      self.identity = lambda x: x\n",
        "    else:\n",
        "      self.identity = layers.Conv2D(out_channel, (1, 1), padding='same')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    return x + self.identity(x)"
      ],
      "metadata": {
        "id": "q6_lrtijI7uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualLayer(tf.keras.Model):\n",
        "  def __init__(self, in_channel, out_channel, kernel_size, stride=False):\n",
        "    super(ResidualLayer, self).__init__()\n",
        "    # residualunit + unit + unit\n",
        "    self.res1 = ResidualUnit(in_channel, out_channel, kernel_size, stride)\n",
        "    self.res2 = ResidualUnit(out_channel, out_channel, kernel_size)\n",
        "    self.res3 = ResidualUnit(out_channel, out_channel, kernel_size)\n",
        "  \n",
        "  def call(self, x):\n",
        "    x = self.res1(x)\n",
        "    x = self.res2(x)\n",
        "    x = self.res3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "15UEkr_7NJtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class cnn_model(tf.keras.Model):\n",
        "  global input_img_shape, input_channel, layer1_output_channel, layer1_kernel_size, res_kernel_size, layer2_output_channel, layer3_output_channel\n",
        "  def __init__(self):\n",
        "    super(cnn_model, self).__init__()\n",
        "    self.num_residual_units = 3 # number of units per layer\n",
        "    self.num_residual_layers = 2 # number of layer per model\n",
        "    self.res_kernel_size = (3, 3)\n",
        "\n",
        "    self.layer1 = models.Sequential(\n",
        "        [layers.Conv2D(layer1_output_channel, layer1_kernel_size, strides=(2, 2), \n",
        "                       padding='same', input_shape=input_img_shape, activation='relu'),\n",
        "         layers.MaxPool2D(pool_size=(2, 2))]\n",
        "    )\n",
        "\n",
        "    self.unit1 = models.Sequential(\n",
        "        [layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    self.unit2 = models.Sequential(\n",
        "        [layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    self.unit3 = models.Sequential(\n",
        "        [layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer2_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    self.unit4 = models.Sequential(\n",
        "        [layers.Conv2D(layer3_output_channel, res_kernel_size, strides=(2, 2), padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    self.unit5 = models.Sequential(\n",
        "        [layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    self.unit6 = models.Sequential(\n",
        "        [layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    self.unit7 = models.Sequential(\n",
        "        [layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU(),\n",
        "         layers.Conv2D(layer3_output_channel, res_kernel_size, padding='same'),\n",
        "         layers.BatchNormalization(),\n",
        "         layers.ReLU()\n",
        "         ]\n",
        "    )   \n",
        "\n",
        "    self.flatten_layer = layers.Flatten()\n",
        "\n",
        "    self.classifier = models.Sequential(\n",
        "        [layers.Dense(4)]\n",
        "    )\n",
        "\n",
        "    self.identity = layers.Conv2D(layer3_output_channel, (1, 1), padding='same', strides=(2, 2))\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x_t = self.unit1(x)\n",
        "    x = x + x_t\n",
        "    x_t = self.unit2(x)\n",
        "    x = x + x_t\n",
        "    x_t = self.unit3(x)\n",
        "    x = x + x_t\n",
        "    x_t = self.unit4(x)\n",
        "    x = self.identity(x) + x_t\n",
        "    x_t = self.unit5(x)\n",
        "    x = x + x_t\n",
        "    x_t = self.unit6(x)\n",
        "    x = x + x_t\n",
        "    x_t = self.unit7(x)\n",
        "    x = x + x_t\n",
        "    x = self.flatten_layer(x)\n",
        "    x = self.classifier(x)\n",
        "    probs = tf.nn.softmax(x)\n",
        "    return probs"
      ],
      "metadata": {
        "id": "oy7m1ziH8YMZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}